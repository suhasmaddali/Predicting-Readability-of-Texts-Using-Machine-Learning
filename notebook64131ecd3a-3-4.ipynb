{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Readability Challenge Machine Learning\n\nIn this machine learning project, we are going to be predicting the difficulty of different texts based on some important features. Since we only have the textual information, we are going to need to create new features and also tokenize the existing words into different words and sentences to understand some useful features. \n\nIn addition to this, we would also find correlation between different features that we have created and see how much of an impact they make when we are performing the machine learning analysis and predictions respectively. ","metadata":{}},{"cell_type":"code","source":"import numpy as np                       ##Used for numerical computations \nimport pandas as pd                      ##Used for reading the data\nimport seaborn as sns                    #Used for plotting with more features\nimport matplotlib.pyplot as plt          #Used for plotting \nfrom nltk.corpus import stopwords        ##This is used to plot the number of stopwords \nfrom nltk.tokenize import word_tokenize, sent_tokenize        ##This is used to divide the overall text data to tokens and sentences\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer   ##Using the vectorizer to convert values\nimport tqdm                        ##Used for measuring the time it takes to get the things done \nimport re                           ##Standard library for reading and substituting the word expressions \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tqdm import tqdm\nimport nltk                                ##Used for the natural language processing tasks \nimport missingno as msno                      ## Used to plot the missing values that are present in our data\nfrom wordcloud import WordCloud               ##It is used to plot the frequency of the words which determines their size\ntry:\n    import plotly.express as px               ##This library is used for interactive visualization \n    from plotly import graph_objects as go    ##We also have to use this along with plotly to get interactive visualization\nexcept:\n    !pip install plotly\nimport warnings                       ##We are going to filer some warnings and remove them when we try to import the libraries\nwarnings.filterwarnings(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-07-24T21:22:16.909368Z","iopub.status.busy":"2021-07-24T21:22:16.908887Z","iopub.status.idle":"2021-07-24T21:22:16.913150Z","shell.execute_reply":"2021-07-24T21:22:16.912459Z","shell.execute_reply.started":"2021-07-24T21:22:16.909332Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we are going to be just looking at the present directory and see the path that we are currently at so that we can understand where our datasets are present. ","metadata":{}},{"cell_type":"code","source":"pwd()","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:22:17.011518Z","iopub.status.busy":"2021-07-24T21:22:17.010996Z","iopub.status.idle":"2021-07-24T21:22:17.019512Z","shell.execute_reply":"2021-07-24T21:22:17.018541Z","shell.execute_reply.started":"2021-07-24T21:22:17.011484Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen below, the train path and the test path are created which would later be used to read the datasets based on where they are present and the path. ","metadata":{}},{"cell_type":"code","source":"##Path used for training and testing data \nTRAIN_PATH = 'Readability datasets/'\nTEST_PATH = 'Readability datasets/'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now is the time to store the .csv files in different variables so that we later can use them for the machine learning analysis and predictions. ","metadata":{}},{"cell_type":"code","source":"##Reading the training data, testing data and sample values that we are going to be understanding and using in the long term. \n\ndf_train = pd.read_csv(TRAIN_PATH + 'train.csv', low_memory = False)\ndf_test = pd.read_csv(TEST_PATH + 'test.csv', low_memory = False)\ndf_sample = pd.read_csv(TEST_PATH + 'sample_submission.csv', low_memory = False)","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:22:24.303679Z","iopub.status.busy":"2021-07-24T21:22:24.303312Z","iopub.status.idle":"2021-07-24T21:22:24.355174Z","shell.execute_reply":"2021-07-24T21:22:24.354338Z","shell.execute_reply.started":"2021-07-24T21:22:24.303649Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is always a good idea to check the memory usage so that there won't be any issues when performing operations that require more RAM. Sometimes when we don't check the usage, there might be a case where the amount of RAM that is being consumed for the machine learning operations far exceeds the capacity of our RAM, leading to errors in the code. Therefore, it would be good to understand the total amount of RAM that is being used respectively. ","metadata":{}},{"cell_type":"code","source":"##info is used to check the total number of null values and also the feature types respectively\ndf_train.info(memory_usage = 'deep')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us now perform the same operation for the test set to understand the data and also see the different columns where there are NULL values present. ","metadata":{}},{"cell_type":"code","source":"df_test.info(memory_usage = 'deep')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Performing the same operation for the sample dataframe to see the type of columns that we must include when doing the submission. ","metadata":{}},{"cell_type":"code","source":"df_sample.info(memory_usage = 'deep')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading the Head of Training Data\n\nNow, we see from the below that there are some columns that contain NULL values such as \"url_legal\" and \"license\" columns respectively. One observation from the table below is that there is only a text that we are given along with the \"target\" which is what we are going to predict for the future text along with \"standard_error\" respectively. \n\nSince there are not many features rather than just the text given, we have to be creating new features that helps us to get the best predictions in the test set. Therefore, we have to featurize based on the text and create now columns and append in our existing dataset which ensures that we get a model that has a good accuracy and low mean square error. ","metadata":{}},{"cell_type":"code","source":"##Reading the head of the dataframe that we are working on. \ndf_train.head()","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:22:42.921087Z","iopub.status.busy":"2021-07-24T21:22:42.920709Z","iopub.status.idle":"2021-07-24T21:22:42.949195Z","shell.execute_reply":"2021-07-24T21:22:42.947799Z","shell.execute_reply.started":"2021-07-24T21:22:42.921054Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking a look at the sample data where we must be giving the specific ID along with the predictions of our machine learning and deep learning algorithms and submit it. ","metadata":{}},{"cell_type":"code","source":"df_sample.head()","metadata":{"execution":{"iopub.execute_input":"2021-07-23T23:33:11.778572Z","iopub.status.busy":"2021-07-23T23:33:11.778241Z","iopub.status.idle":"2021-07-23T23:33:11.790072Z","shell.execute_reply":"2021-07-23T23:33:11.788929Z","shell.execute_reply.started":"2021-07-23T23:33:11.778543Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Missingno to plot the missing null values\nIt would be a good idea to understand the missing values that are present in our data with the help of a figure. Below, we are going to be using the missingno library which gives us the missing values that are present based on different columns respectively. We see that there are a few missing values that are present in the columns \"url_legal\" and \"license\" respectively as marked below. \n\nIn addition, we can also find that there are no missing values present for \"excerpt\", \"target\" and \"standard_error\" respectively. ","metadata":{}},{"cell_type":"code","source":"##Using the missingno library that is used to get the list of missing values through a figure. \nmsno.matrix(df_train, color = (0.01, 0.75, 0.75))","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:25:57.680892Z","iopub.status.busy":"2021-07-24T21:25:57.680417Z","iopub.status.idle":"2021-07-24T21:25:58.115142Z","shell.execute_reply":"2021-07-24T21:25:58.114348Z","shell.execute_reply.started":"2021-07-24T21:25:57.680860Z"},"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Useful Functions\nIt would be a good idea to create functions and add some of the arguments so that we don't have to repeat the code again. In addition, we can just change the arguments and it would be applied entirely to the block that of code that is present in the function. Therefore, it would be really convenient to create functions along with useful arguments that we might change when we are implemented them in the future of our code. \n\nBelow, we have defined a function called \"plot_histogram\" where it takes in the dataframe along with the column that we are interested and a few other arguments and plot a histogram of our configuration. ","metadata":{}},{"cell_type":"code","source":"def plot_histogram(dataframe: pd.DataFrame, column: str, x_title = None, y_title = None, edge_color = 'black', \n                   color = 'Green', total_bins = 20, font_size = 10):\n    \"\"\"\n    In this function, we are going to plot a histogram for the dataframe that is given\n    along with some modifications and different features of histogram plot\n    \"\"\"\n    \n    fig, ax = plt.subplots(figsize = (10, 5))    ##This is used to create many plots depending on which we choose to use respectively.\n    ax.hist(dataframe[column], bins = total_bins, edgecolor = edge_color, color = color)\n    ax.set_title(f'Histogram Distribution of {column} values', fontsize = font_size + 5)\n    ax.set_xlabel(column, fontsize = font_size)\n    ax.set_ylabel(\"Total Number of Observations\", fontsize = font_size)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Histogram of Target Variable\nSince most of the parameters are set to default values, those values are taken into consideration when plotting the histogram plots respectively. Since we want to look at the column called 'target' in our data and it's distribution, we are using that column and giving it to the function so that it plots respectively. \n\nWe see that the output is evenly distributed with the mean around -1. In addition, we find that there are very few values that are present that are greater than 1 or less than -3 as can be seen from the below plot. ","metadata":{}},{"cell_type":"code","source":"##Plotted the histogram of the variable that we are going to be predicting respectively. \nplot_histogram(df_train, column = 'target')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Histogram of Standard_Error Values\nIn the same light, let us now look at the standard error distribution by using the function that we have created to plot the histogram. Now we have changed the color to see the changes and how they would be applied to the block of functions. \n\nThere are a lot of values that are present around 0.5 than the other regions. We understand that there are very few values where the standard error is 0.6 or more. In addition, there are very few values where the standard error is below 0.4 respectively.  ","metadata":{}},{"cell_type":"code","source":"#Using the histogram values and we are going to plot the standard error in orange as can be seen below\nplot_histogram(df_train, column = 'standard_error', color = 'orange')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Reading the text that we want to see and looking at how the sentences are framed.\ndf_train['excerpt'].iloc[1]","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:23:56.229878Z","iopub.status.busy":"2021-07-24T21:23:56.229433Z","iopub.status.idle":"2021-07-24T21:23:56.235275Z","shell.execute_reply":"2021-07-24T21:23:56.234620Z","shell.execute_reply.started":"2021-07-24T21:23:56.229850Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Replacing a few characters that may not be useful for our machine learning predictions respectively. \ndf_train['excerpt'].apply(lambda text: text.replace('\\n', ' ')).iloc[1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['excerpt'] = df_train['excerpt'].apply(lambda text: text.replace('\\n', ' '))\ndf_test['excerpt'] = df_test['excerpt'].apply(lambda text: text.replace('\\n', ' '))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['excerpt'].iloc[1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Wordcloud function\n\nWe are going to be creating a wordcloud function that is important for machine learning. We are going to be using that function to create words and understand their frequency based on the size of those words respectively. Since it would be a good idea to use wordcloud in a function so that we could use the same block of code again.\n\nFrom the observation, we see that there are a few words such as \"One\" and \"said\" that are frequently occurring in our dataset. We were able to understand this with the help of the size of the words that are present in the wordcloud that indicate their frequency respectively. We also consider \".\" as a word and we see that it is also frequently occurrring respectively. There are some words that don't occur as much as the above mentioned words such as \"country\" and \"never\". \n\nTherefore, we were able to get a good understanding of the wordcloud figure and see the frequency of the occurence of the words based on the size in the figure given by the wordcloud. ","metadata":{}},{"cell_type":"code","source":"def wordcloud_function(df, title, column, fontsize = 15, \n                       figsize = (10, 10), width = 300, height = 300):\n    \"\"\"\n    This function ensures that we get the size of the words based on their occurance \n    and we are going to use a figure to plot it in this function respectively. \n    \"\"\"\n    total_text = ''.join([text for text in df[column]])\n    wordcloud = WordCloud(width = width, height = height).generate(total_text)\n    plt.figure(figsize = figsize)\n    plt.imshow(wordcloud)\n    plt.title(title, fontsize = fontsize)\n    plt.show()\nwordcloud_function(df_train, title = \"Wordcloud function\", column = \"excerpt\")\n    ","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:46:30.431360Z","iopub.status.busy":"2021-07-24T21:46:30.431057Z","iopub.status.idle":"2021-07-24T21:46:32.594747Z","shell.execute_reply":"2021-07-24T21:46:32.593870Z","shell.execute_reply.started":"2021-07-24T21:46:30.431331Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it is time to create a preprocessing function that would take into account the text and convert it in the form where the machine learning and deep learning models could use quite easily. Therefore, we are going to take that data and ensure that we understand how the machine learning models are going to perform in the future. \n\nIn preprocessing function, we would just replace the punctuations and other things with only the text present in the excerpt. Later, we would lowercase the words and then remove the stopwords. Once the stopwords are removed, we are going to be lemmatizing those words (reducing words to their base form) so that their stem is retained along with taking the context. We would return the output as a list. ","metadata":{}},{"cell_type":"code","source":"len(df_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_train) * 0.7","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_train) * 0.75","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating preprocessing function\nIt is now time to understand the data and convert the essay values to different set of values that could be given to different vectorizers that are important for machine learning respectively. We would be performing various operations when we are creating this function. We would take the text and replace all the values with only alphabets. Later, we are going to lowercase the text and then tokenize and then, remove the stopwords that do not add a lot of meaning to the text. Finally, a dataframe is constructed and returned as output from the function. ","metadata":{}},{"cell_type":"code","source":"def preprocessing_function(df):\n    \"\"\"\n    This function takes into consideration the dataframe and extracts the text.\n    In addition, it makes modifications to the text and converts it to a simpler form\n    for machine learning processing respectively.\"\"\"\n    \n    text_list = []\n    for text in tqdm(df['excerpt'].values):\n        text = re.sub('[^a-zA-Z]', ' ', text)\n        text = text.lower()\n        text = nltk.word_tokenize(text)\n        [word for word in text if not word in set(stopwords.words(\"english\"))]\n        lemmatizer = nltk.WordNetLemmatizer()\n        text = [lemmatizer.lemmatize(word) for word in text]\n        text = \" \".join(text)\n        text_list.append(text)\n    text_list = pd.Series(text_list)\n    text_list.column = ['Converted_text']\n    return text_list\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to store the output that is given by the preprocessing function into a variable and later use it. ","metadata":{}},{"cell_type":"code","source":"preprocessed_text = preprocessing_function(df_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_text_test = preprocessing_function(df_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining get_useful_features functions\n\nIt is now time to get the useful features that are important for machine learning. We would have to be creating new features that would help the machine learning models to get the best predictions for the difficulty of the text. \n\nTaking into consideration the excerpt and stopwords, we are going to be creating new feautres such as total number of words, sentence length, overall change in the text length and other features that are important for getting the machine learning outputs. The function would return the final dataframe that contains all the preprocessed output along with the newly created features that are important for machine learning. ","metadata":{}},{"cell_type":"code","source":"def get_useful_features(df, stop_words):\n    \"\"\"\n    The function would take the dataframe and stopwords and then, convert the excerpts into different features\n    such as the number of sentences, words and the lenght of the lemmas created along with the overall preprocessed\n    essay length.\"\"\"\n    sentences = []\n    num_of_words = []\n    sent_length = []\n    word_length = []\n    lemma_length = []\n    num_of_lemmas = []\n    preprocessed_essay_length = []\n    initial_text_length = []\n    num_of_sentences = []\n    text_shortage = []\n    \n    for text in tqdm(df['excerpt'].values):\n        \n        initial_length = len(text)\n        initial_text_length.append(initial_length)\n        num_sentences = len(sent_tokenize(text))\n        num_of_sentences.append(num_sentences)\n        text = re.sub('[^a-zA-Z]', ' ', text)\n        text = text.lower()\n        text = word_tokenize(text)\n        num_words = len(text) \n        num_of_words.append(num_words)\n        sent_length.append(num_words/num_sentences)\n        word_length.append(initial_length/num_words)\n        text = [word for word in text if not word in stop_words]\n        lemmatizer = nltk.WordNetLemmatizer()\n        text = [lemmatizer.lemmatize(word) for word in text]\n        #print(text)\n        num_lemmas = len(text)\n        num_of_lemmas.append(num_lemmas)\n        text = \" \".join(text)\n        #print(text)\n        preprocessed_essay_length_value = len(text)\n        preprocessed_essay_length.append(preprocessed_essay_length_value)\n        #print(preprocessed_essay_length)\n        #print(num_lemmas)\n        lemma_length.append(preprocessed_essay_length_value/num_lemmas)\n        \n        text_shortage.append(preprocessed_essay_length_value/initial_length)\n        \n    final_df = pd.concat([pd.Series(sent_length), pd.Series(num_of_words),\n                             pd.Series(word_length), pd.Series(lemma_length),\n                             pd.Series(num_of_sentences), pd.Series(initial_text_length),\n                             pd.Series(num_of_lemmas), pd.Series(preprocessed_essay_length),\n                             pd.Series(text_shortage)], axis = 1)\n    final_df.columns = [\"sentence_length\", \"num_of_words\", \"word_length\",\n                           \"lemma_length\", \"num_of_sentences\",\n                           \"initial_text_length\", \"num_of_lemmas\",\n                           \"preprocessed_essay_length\", \"text_shortage\"]\n    \n    return final_df\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are now going to store those values into a variable that we can use to check the values respectively. ","metadata":{}},{"cell_type":"code","source":"final_df = get_useful_features(df_train, stop_words = set(stopwords.words(\"english\")))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df_test = get_useful_features(df_test, stop_words = set(stopwords.words(\"english\")))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have created a dataframe and we see that there are different features that we are going to be giving to the machine learning models for predictions. We have converted the text in the form of different useful features such as the number of words, average word and sentence length, number of lemmas created and preprocessed essay length. Overall, this could be given to the machine learning models for prediction where the target which is nothing but the difficulty of the text would be predicted using machine learning. ","metadata":{}},{"cell_type":"code","source":"final_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pairplot of Different Features \n\nIt would be a good idea to see the pairplots which are nothing but a group of scatterplots where the values are spread based on the 2 features that are considered at hand. By looking at this pairplot, one would understand if there is any correlation between features and their values and spread respectively. \n\nWhen we get an almost a linear spread between features, we can understand that there is either a positive correlation or a negative correlation between the features at hand. \n\nBased on the observation, we see that there is a good correlation between number of words and intial text length. There is also a good positive correlation between the number of words and the text shortage metric that we have created. In addition, there is also a positive correlation between the lemma word average length and the overall average length of word before lemmatization. This tells us that based on how long the word is, the lemma form of the word would almost have identical size respectively. \n\nOne more thing to observe based on the text values is that there is a slight negative correlation between the initial text length and the difficulty of the text. We can understand this to be true as when there are a lot of words in a sentence, it becomes easy to understand the text as the author usually would elaborate the points that he/she made and this ensures that there is clarity in the text and it being less difficult. More observations could be made using the pairplot function in seaborn. For now, we have made a good amount of useful observations that are important when doing the machine learning analysis. ","metadata":{}},{"cell_type":"code","source":"df_for_plotting = pd.concat([final_df, df_train[\"target\"]], axis = 1)\nax = sns.pairplot(data = df_for_plotting, plot_kws = dict(color = \"maroon\"))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.zeros_like((3, 3))","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:24:09.392325Z","iopub.status.busy":"2021-07-24T21:24:09.391826Z","iopub.status.idle":"2021-07-24T21:24:09.405666Z","shell.execute_reply":"2021-07-24T21:24:09.404548Z","shell.execute_reply.started":"2021-07-24T21:24:09.392293Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heatmap of Correlation Matrix\n\nWhen we are using .corr(), we are going to get the correlation values for different features in a form of a table. Since interpreting a table is quite difficult especially with float values present, it would be a good idea to visualize the data and color the points based on their values.\n\nThis is done with the aid of heatmap where based on the values present, they would change the intensity of their color. Below is a heatmap plotted that gives us a good idea about the correlation between different features that are important for machine learning. \n\nBy observing the values below, one could get an understand there is a slight negative correlation between lemma_length and the difficulty of the text. In addition, we also see a negative correlation between average word length and the text's difficulty respectively. We see that there is also a clear negative correlation between sentence length and number of sentences. This means that as the number of sentences increase, there is a higher possibility that there can be a high sentence length. However, this does not mean that correlation is equal to causation. But based on the information and the context, we might assure that there is causation between features respectively. ","metadata":{}},{"cell_type":"code","source":"correlation = df_for_plotting.corr()\nplt.figure(figsize = (10, 10))\nsns.heatmap(correlation, annot = True, cmap = 'Oranges', linewidths = 1,\n           annot_kws = {\"weight\": \"bold\", \"fontsize\": 10})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatterplot function\n\nIt would be a good idea to create scatterplot function that ensures that we are able to change the parameters that are important for machine learning. We see that we might give the default parameters that are important for the scatterplot. However, we have the freedom to change the parameters as and when needed when calling the function.\n\nSince the function would only be used for plotting rather than returning any output, there is no return in a function. ","metadata":{}},{"cell_type":"code","source":"def scatterplot_function(df: pd.DataFrame, X, Y, figsize = (10, 10), color = 'orange'):\n    plt.figure(figsize = figsize)\n    sns.scatterplot(data = df, x = X, y = Y, color = color)\n    plt.title(f'Scatterplot between {X} and {Y}')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatterplot between num_of_sentences and target\n\nBy looking at the heatmap above, we have considered the correlation between features and seen if there is any relationship between the features.\n\nNow, we would be focusing on the scatterplot between 'num_of_sentences' and 'target' respectively. Below, we see that there is a slight positive relationship between the output and the \"num_of_sentences\" feature. This could help us understand that there might be a change that when there is increase in the number of sentences, there is a possibility of the difficulty of the text would also increase. But let us not jump to the conclusion as correlation might not always be equal to causation. Hence, let us now explore more features which would ensure that we understand them and we are going to be using them. ","metadata":{}},{"cell_type":"code","source":"scatterplot_function(df_for_plotting, X = 'num_of_sentences', Y = 'target', figsize = (7, 7))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatterplot between 'preprocessed_essay_length' and 'num_of_lemmas'\n\nNow, we are going to plot between 'preprocessed_essay_length' and 'num_of_lemmas' as we have seen that their correlation value is about 0.86 respectively. Therefore, we have plotted the scatterplot to understand the values respectively. We see that there is a good correlation between the features as there is not much scatter between the 2 features that we have considered.\n\nLemmas are the words that are created after preprocessing the actual words and replacing those words with their stems but also considering the context at which those words appear. This ensures that we get the right stems that later could be vectorized and given to the machine learning models for processing and prediction respectively. \n","metadata":{}},{"cell_type":"code","source":"scatterplot_function(df_for_plotting, X = 'preprocessed_essay_length', Y = 'num_of_lemmas', figsize = (7, 7), color = 'maroon')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"scatterplot_function(df_for_plotting, X = 'word_length', Y = 'text_shortage', figsize = (7, 7), color = 'green')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatterplot_function(df_for_plotting, X = 'num_of_sentences', Y = 'sentence_length', figsize = (7, 7), color = 'black')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(df_train['excerpt'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_for_plotting.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating new function that generates more features\n\nWe are going to create a function that would create more features such as counting the number of commas, semicolons and other important features that are important for machine learning analysis. We would have to create empty lists of these values and we are going to concat those by converting them into series and then, return a new dataframe respectively. \n\nWith the help of this function, we have created new dataframe which contains the useful columns that are important for machine learning respectively. We would be performing the feature analysis and thise ensures that we are going to be getting the best results on the test set respectively. \n\nAt last, we are going to concat those values that are important for machine learning and this would ensure that we get the best results in the test set respectively. We are going to be taking those values and this ensures that we are getting the best results on the test set. ","metadata":{}},{"cell_type":"code","source":"def generate_more_features(df: pd.DataFrame):\n    \"\"\"\n    This function would create a dataframe of different useful features\n    that are important for machine learning predictions respectively.\n    \"\"\"\n    commas = []\n    semicolon = []\n    exclamations = []\n    questions = []\n    quotes = []\n    periods = []\n    longest_word = []\n    \n    for i in range(len(df)):\n        \n        #word_len = []\n        text = df['excerpt'].iloc[i]\n        commas.append(text.count(\",\"))\n        semicolon.append(text.count(\";\"))\n        exclamations.append(text.count(\"!\"))\n        questions.append(text.count(\"?\"))\n        quotes.append(text.count('\"'))\n        periods.append(text.count('.'))\n        word_len = [len(w) for w in text.split(\" \")]\n        longest_word.append(np.max(word_len))\n        \n    df_with_features =pd.concat((pd.Series(commas), pd.Series(semicolon), pd.Series(exclamations),\n                               pd.Series(questions), pd.Series(quotes), pd.Series(periods),\n                                pd.Series(longest_word)), axis = 1)\n    df_with_features.columns = [\"num_of_commas\", \"num_of_semicolons\", \"num_of_explamations\",\n                                \"num_of_questions\", \"num_of_quotes\", \"num_of_periods\", \n                                \"longest_word\"]\n                                \n    return df_with_features","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We would be using those functions and we are going to be taking those values in a variable respectively. ","metadata":{}},{"cell_type":"code","source":"df_with_more_features = generate_more_features(df_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_with_more_features_test = generate_more_features(df_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reading the head of the dataframe, we see that there are different columns created along with the numerical representation respectively. Therefore, we have created a new dataframe in the above function and we have created some important features that could be used for machine learning analysis. ","metadata":{}},{"cell_type":"code","source":"df_with_more_features.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are now going to check whether there are any null values that are present in the newly created dataframe. We see below that there are some values that are null present in our dataframe. Therefore, we have to take our time to remove those null values so that we are going to be using the things that we are sure that the more we are learning in the long term. ","metadata":{}},{"cell_type":"code","source":"any(df_with_more_features.isnull())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to be creating the dataframe where there are null or not values that we are going to be using. ","metadata":{}},{"cell_type":"code","source":"df_with_more_features.isnull()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to be taking a look at the null values and we are going to understand the different machine learning information respectively. ","metadata":{}},{"cell_type":"code","source":"df_with_more_features.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to read the head of the dataframe and see the values and how they are spread out. ","metadata":{}},{"cell_type":"code","source":"df_with_more_features.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['excerpt'].iloc[140]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['excerpt'].iloc[143]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_for_plotting = pd.concat([df_with_more_features, df_train['target']], axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pairplot of Other Features\n\nUnderstanding some of the pairplots, we are going to use them to see how the values are spread. We could see one positive correlation between the difficulty of the text and the \"num_of_periods\" that we have in our data. This means that more the number of sentences, there is a higher change for the text to be difficult to a certain extent. \n\nIn addition to this, we also see that there is a relationship between the number of quotes and the difficulty of the text. We see quite a linear relationship between the features as can be seen. \n\nThere is also a positive relationship between the number of questions and the difficulty of the text respectively. Therefore, by looking at the pairplot, we see that there are some features that are quite useful when doing the machine learning analysis respectively.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df_for_plotting, plot_kws = dict(color = 'green'))\nplt.show()\n","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heatmap between num_of_quotes and num_of_questions\n\nSince we have created new features, let us see how these features are related to each other and the output variable respectively. We make some interesting observations by looking at the heatmap below. \n\n1. The feature num_of_explanations is quite related to num_of_quotes as can be seen in the heatmap below. \n2. We see that the num_of_questions are quite related to the num_of_quotes as well. \n3. There is a negative correlation between the num_of_semicolons and the num_of_periods.\n4. num_of_quotes and num_of_periods are quite positively correlated with the difficulty of the text. \n5. There is also a negative correlation between the length of the longest word and the difficulty of the text. \n\nWith the help of heatmap, therefore, we were able to make some interesting observations above. ","metadata":{}},{"cell_type":"code","source":"df_correlation = df_for_plotting.corr()\nplt.figure(figsize = (10, 10))\nsns.heatmap(df_correlation, annot = True, cmap = 'Oranges', linewidths = 1,\n           annot_kws = {\"weight\": \"bold\", \"fontsize\": 10})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_with_more_features.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_more_features(df_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['excerpt_length'] = df_train.excerpt.apply(len)\ndf_test['excerpt_length'] = df_test.excerpt.apply(len)","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:29:56.165843Z","iopub.status.busy":"2021-07-24T21:29:56.165285Z","iopub.status.idle":"2021-07-24T21:29:56.171736Z","shell.execute_reply":"2021-07-24T21:29:56.170915Z","shell.execute_reply.started":"2021-07-24T21:29:56.165810Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.execute_input":"2021-07-24T21:30:34.783461Z","iopub.status.busy":"2021-07-24T21:30:34.782882Z","iopub.status.idle":"2021-07-24T21:30:34.796608Z","shell.execute_reply":"2021-07-24T21:30:34.795594Z","shell.execute_reply.started":"2021-07-24T21:30:34.783417Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Count_Vectorizer(df: pd.DataFrame):\n    vectorizer = CountVectorizer()\n    vectorizer.fit(df['excerpt'])\n    converted_vector = vectorizer.transform(df['excerpt'])\n    return converted_vector","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Count_Vectorizer(df_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Decontracted function \nWe are going to be creating this function which would take the actual subtext values and convert to forms that are easily accessible to the reader. Some of the words can be seen below from the function where the short forms are replaced with more useful texts respectively. This function is created so that the output from this could be given to other function that we are going to create just below this function. ","metadata":{}},{"cell_type":"code","source":"# https://stackoverflow.com/a/47091490/4084039\nimport re\n\ndef decontracted(phrase):\n    \"\"\"\n    This function would convert some short letters into the forms that one \n    could easily understand respectively.\n    \"\"\"\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating preprocessing_function\nIt is now time to create the preprocessing function that takes into account the dataframe and it would be removing the stopwords from the text. Later, it would be replacing those complex words that we have seen above with the easy words that are easier to preprocess and understand. Later, lemmatization is done which would replace the words into simpler forms so that they could be given to different machine learning and deep learning models to generate the output respectively. ","metadata":{}},{"cell_type":"code","source":"def preprocessing_function(df):\n    \"\"\"\n    In this function, we are going to be performing the basic preprocessing \n    which is needed before giving to different vectorizers. This ensures that\n    we are getting the best output values respectively.\n    \"\"\"\n    \n    stopwords_new = set(stopwords.words('english'))\n    text_list = []\n    for i in tqdm(range(len(df['excerpt']))):\n        text = df['excerpt'].iloc[i]\n        text = decontracted(text)\n        text = re.sub('[^a-zA-Z]', ' ', text)\n        text = text.lower()\n        text = [word for word in text.split(' ') if not word in stopwords_new]\n        lemmatizer = nltk.WordNetLemmatizer()\n        text = [lemmatizer.lemmatize(word) for word in text]\n        text_list.append(' '.join(text))\n    return text_list\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to take the values that are given by the function and store it in a variable as can be seen below. ","metadata":{}},{"cell_type":"code","source":"df_train_preprocessed = preprocessing_function(df_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similar process is applied to the test set so that we might make predictions with the best machine learning or deep learning model that we would be getting as the output. ","metadata":{}},{"cell_type":"code","source":"df_test_preprocessed = preprocessing_function(df_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Taking a look at the head of the preprocessed that we got from the function and stored in this variable. ","metadata":{}},{"cell_type":"code","source":"preprocessed_text.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_with_more_features.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_for_plotting.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Concatenating the dataframes\n\nWe are going to be concatenating the dataframes that we have created previously. Taking some important features and the overall output values, we are later going to be generating the predictions that are important for machine learning outputs respectively. ","metadata":{}},{"cell_type":"code","source":"df_complete = pd.concat((preprocessed_text, df_with_more_features, final_df), axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are also going to be doing the same thing for the test set. Considering the test set, we have to later apply the overall process that we have created for the training data. When we are done with the output values, we are going to be taking those new values which would ensure that we get the best output values respectively. ","metadata":{}},{"cell_type":"code","source":"df_complete_test = pd.concat((preprocessed_text_test, df_with_more_features_test, final_df_test), axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We would be looking at the dataframe we got above and looking at some of the columns that we have taken into consideration. ","metadata":{}},{"cell_type":"code","source":"df_complete.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are going to also see how the test set values are generated. ","metadata":{}},{"cell_type":"code","source":"df_complete_test.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_text.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\narray_output_values = vectorizer.fit_transform(preprocessed_text)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Sequential","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nvectorizer.fit(df_train['excerpt'])\ndf_train_converted = vectorizer.transform(df_train['excerpt'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_converted","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_converted","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_complete.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_complete_test.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_complete_important_features = df_complete.iloc[:, 1:]\ndf_complete_important_features_test = df_complete_test.iloc[:, 1:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_complete_important_features.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating min_max_scaler function\n\nWith the help of this function, the training and the test values are converted to scaled outputs where the minimum value is 0 and the maximum value is 1 respectively. In other words, this function would just be converting those high values to lie between 0 and 1. ","metadata":{}},{"cell_type":"code","source":"def min_max_scaler(df_train, df_test):\n    \"\"\"\n    This function performs the scaling operation by taking into account the train and test set respectively. It is going to \n    convert the values that are present in the data to lie between 0 and 1 respectively.\n    \"\"\"\n    scaler = MinMaxScaler()\n    scaler.fit(df_train)\n    df_scaled = scaler.transform(df_train)\n    df_scaled_test = scaler.transform(df_test)\n    return df_scaled, df_scaled_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Tfidf_Vectorier function\nThis function would convert the training and the test values to Tfidf vectors that are important for machine learning analysis in the future respectively. Therefore, the text document is converted into a group of vectors that is easy for the machine learning and deep learning models to perform well on the training and the test data.\n\nWe have to note that the machine learning models would be working with only the numerical data rather than any other sort of data such as text and other forms of data. Hence, steps must be taken to ensure that the values that are given to the machine learning models are numerical in nature. ","metadata":{}},{"cell_type":"code","source":"def Tfidf_Vectorizer(df_train, df_test):\n    \"\"\"\n    This function would take the training data and the test data and convert those values which would be in the form of text \n    to tfidf values that could be later used for machine learning analysis.\n    \"\"\"\n    vectorizer = TfidfVectorizer()\n    df_vectorized_train = vectorizer.fit_transform(df_train)\n    df_vectorized_test = vectorizer.transform(df_test)\n    return df_vectorized_train, df_vectorized_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Count_Vectorizer function \nIn the count vectorizer function, the original text document both for the training and the test sets are taken and we are going to be converting those values Bag-Of-Words (BOW) representation that would be later given to the machine learning models for prediction. ","metadata":{}},{"cell_type":"code","source":"def Count_Vectorizer(df_train, df_test):\n    \"\"\"\n    This function would take the training data and the test data and convert those values which would be in the form of text to \n    bag of words representation or count vectorized values which are later used for machine learning prediction.\n    \"\"\"\n    vectorizer = CountVectorizer()\n    df_vectorized_train = vectorizer.fit_transform(df_train)\n    df_vectorized_test = vectorizer.transform(df_test)\n    return df_vectorized_train, df_vectorized_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_complete_important_features\ndf_complete_important_features_test\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_converted","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scaled, df_scaled_test = min_max_scaler(df_complete_important_features, df_complete_important_features_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating Vectorizer_decision function\nThis function would give the user whether he/she should be using the Count Vectorizer or the Tfidf Vectorizer that is being used for machine learning. Therefore, they have the freedom to select the type of vectorizer which might be given to the dataframe which would later be used for predictions. \nThe Vectorizer decision would use the above functions which we have created and this would be the main function that would take into account all the values that are present respectively. ","metadata":{}},{"cell_type":"code","source":"def Vectorizer_decision(df_train, df_test):\n    print(\"Please enter the vectorizer that you would like to use for your data\")\n    print(\"Please select from the following options\")\n    print(\"1. Count Vectorizer\")\n    print(\"2. Tfidf Vectorizer\")\n    choice = int(input(\"Enter 1 or 2:\"))\n    type(choice)\n    if choice != 1 and choice != 2:\n        choice = input(\"Please select only from the listed options\")\n        vectorized_train = 0\n        vectorized_test = 0\n    elif choice == 1:\n        print(\"Count Vectorizer Selected\")\n        vectorized_train, vectorized_test = Count_Vectorizer(df_train.iloc[:, 0], df_test.iloc[:, 0])\n    else:\n        print(\"Tfidf Vectorizer Selected\")\n        vectorized_train, vectorized_test = Tfidf_Vectorizer(df_train.iloc[:, 0], df_test.iloc[:, 0])\n    return vectorized_train, vectorized_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Storing the vectorizer outputs in different variables respectively. ","metadata":{}},{"cell_type":"code","source":"df_vectorized, df_vectorized_test = Vectorizer_decision(df_complete.copy(), df_complete_test.copy())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the output that we got is a sparse matrix after giving to the vectorizers, it is important to convert those values to numpy vectors before performing the machine learning tasks. ","metadata":{}},{"cell_type":"code","source":"df_vectorized = df_vectorized.toarray()\ndf_vectorized_test = df_vectorized_test.toarray()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scaled","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"X = np.concatenate((df_vectorized, df_scaled), axis = 1)\nX_test = np.concatenate((df_vectorized_test, df_scaled_test), axis = 1)\ny = df_train['target'].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3, random_state = 50)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def neural_network(X_train, y_train, Validation_data = None, metrics = ['mean_squared_error', 'mean_absolute_error'], \n                   activation = 'relu', input_shape = (22690, ), optimizer = 'adam', loss = 'mean_squared_error',\n                  epochs = 10, batch_size = 64):\n    \"\"\"\n    We are defining a neural network function that takes into account a different set of parameters\n    that are needed to build the machine learning model and we are also giving different values\n    and it would be working with different parameters and we are able to give those values to our \n    deep learning models and we are going to return the output given by the model respectively.\n    \"\"\"\n    \n    model = Sequential()\n    model.add(Dense(500, activation = activation, input_shape = input_shape))\n    model.add(Dense(100, activation = activation))\n    model.add(Dense(50, activation = activation))\n    model.add(Dense(10, activation = activation))\n    model.add(Dense(5, activation = activation))\n    model.add(Dense(1))\n    model.compile(loss = loss, metrics = metrics, optimizer = optimizer)\n    if Validation_data:\n              model.fit(x = X_train, y = y_train, validation_data = Validation_data, epochs = epochs, batch_size = batch_size)\n    else:\n              model.fit(x = X_train, y = y_train, epochs = epochs, batch_size = batch_size)\n    return model ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = neural_network(X_train = X_train, y_train = y_train, Validation_data = (X_cv, y_cv))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TFIDF Vectorizer","metadata":{}},{"cell_type":"markdown","source":"We are going to be using the Tfidf vectorizer that would give us a good understanding of the performance of the neural network model. ","metadata":{}},{"cell_type":"code","source":"df_vectorized, df_vectorized_test = Vectorizer_decision(df_complete, df_complete_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_vectorized = df_vectorized.toarray()\ndf_vectorized_test = df_vectorized_test.toarray()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_vectorized)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.concatenate((df_vectorized, df_scaled), axis = 1)\nX_test = np.concatenate((df_vectorized_test, df_scaled_test), axis = 1)\ny = df_train['target'].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3, random_state = 50)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = neural_network(X_train = X_train, y_train = y_train, Validation_data = (X_cv, y_cv))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def actual_vs_predictions_dataframe(dataframe1, dataframe2, column1 = 'predicted', column2 = 'actual'):\n    dataframe1 = pd.DataFrame(pd.Series(dataframe1), columns = [column1])\n    dataframe2 = pd.DataFrame(pd.Series(dataframe2), columns = [column2])\n    dataframe_concatenated = pd.concat((dataframe1, dataframe2), axis = 1)\n    return dataframe_concatenated","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def regression_plot_function(dataframe, fig_size = (10, 10), color = 'teal'):\n    plt.figure(figsize = fig_size)\n    sns.regplot(data = dataframe, y = 'predicted', x = 'actual', color = color, marker = 'o')\n    plt.title(\"Comparision of predicted values and the actual values\", fontsize = 20)\n    plt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_cv_predictions = model.predict(X_cv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_dataframe = actual_vs_predictions_dataframe(y_cv_predictions.flatten(), y_cv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regression_plot_function(final_dataframe)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The mean squared error of neural network model for cross-validation data is {}\".format(mean_squared_error(y_cv_predictions, y_cv)))\nprint(\"The mean absolute error of neural network model for cross-validation data is {}\".format(mean_absolute_error(y_cv_predictions, y_cv)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Regression Machine Learning Model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_cv_predictions = model.predict(X_cv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_absolute_error(y_cv_predictions, y_cv)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The mean squared error of linear regression model for cross-validation data is {}\".format(mean_squared_error(y_cv_predictions, y_cv)))\nprint(\"The mean absolute error of linear regression modle for cross-validation data is {}\".format(mean_absolute_error(y_cv_predictions, y_cv)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_dataframe = pd.DataFrame(pd.Series(y_cv), columns = ['y_actual'])\nsecond_dataframe = pd.DataFrame(pd.Series(y_cv_predictions), columns = ['y_predictions'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_dataframe = pd.concat((first_dataframe, second_dataframe), axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_dataframe.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#What are some things that we are going to be using in the long term. ","metadata":{},"execution_count":null,"outputs":[]}]}